{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36bf1b8e",
   "metadata": {},
   "source": [
    "(copt)=\n",
    "\n",
    "# Задачи комбинаторной оптимизации\n",
    "\n",
    "Автор(ы):\n",
    "\n",
    "- [Синченко Семен](https://github.com/SemyonSinchenko)\n",
    "\n",
    "\n",
    "В [обзоре квантовых алгоритмов](../../qcalgo/ru/quantum_algorithms_overview.html#id2) мы уже касались темы задач, для которых не существует эффективных классических алгоритмов, а сегодня разберем еще больше примеров. В конце кратко обсудим пару способов, как решать такие задачи на классических компьютерах, а также в чем их принципиальные проблемы и ограничения.\n",
    "\n",
    "Лекция будет построена так:\n",
    "\n",
    "- задача о максимальном разрезе в графе;\n",
    "- задача о выделении сообществ в графе;\n",
    "- задача о Гамильтоновых циклах и коммивояжере;\n",
    "- задача о рюкзаке;\n",
    "- жадные алгоритмы;\n",
    "- метод имитации отжига.\n",
    "\n",
    "Какого-то сложного кода или больших формул с дираковскими значками из квантовой механики тут не будет, так что можно немного передохнуть, расслабиться и насладиться чтением. Для тех, кто хорошо знаком с задачами целочисленной оптимизации, в этой лекции точно не будет ничего нового, и ее можно будет пропускать, ну или пролистать по диагонали.\n",
    "\n",
    "## Задача о максимальном разрезе в графе\n",
    "\n",
    "Мы уже немного говорили об этой задаче в лекции про [модель Изинга](../../problems/ru/ising.html#id3) из-за их очень большого сходства. Но давайте еще раз вспомним, что это за модель такая. Ну и сразу рассмотрим ее максимально общий случай. Итак, у нас есть граф на множестве вершин $V$, связанных множеством ребер $E$. Каждое ребро имеет две инцидентных вершины $u,v$; в общем случае порядок $u,v$ важен, тогда мы говорим о направленном (_directed_) графе. Каждому ребру можно также сопоставить действительное число $w$, тогда у нас будет так называемый _взвешенный_ граф. Наша цель -- разбить множество вершин $V$ на два непересекающихся сообщества $V_1, V_2$. Давайте сформулируем функцию стоимости:\n",
    "\n",
    "$$\n",
    "C = \\sum_{u,v,w \\in E} w (\\mathbf{1}(u \\in V_1, v \\in V_2) + \\mathbf{1}(u \\in V_2, v \\in V_1))\n",
    "$$\n",
    "\n",
    "То есть в общем случае это просто сумма всех весов ребер между двумя сообществами. В общем случае эта задача является $NP$-полной. В теории к этой задаче можно также свести любую другую $NP$ задачу за полиномиальное время.\n",
    "\n",
    "```{figure} /_static/problems/ru/ising/Max-cut.png\n",
    ":width: 400px\n",
    ":name: MaxCut2\n",
    "\n",
    "Иллюстрация задачи о максимальном разрезе в графе\n",
    "```\n",
    "\n",
    "## Задача о выделении сообществ в графах\n",
    "\n",
    "Задача о выделении сообщества в графах это уже более практическая и понятная задача. Она находит применение во многих областях, но одно из самых очевидных применений -- это социология (в том числе анализ социальных сетей), когда мы хотим, анализируя контакты людей, выделить из них сообщества для дальнейшего анализа. Эта задача также является $NP$-трудной, так как существует экспоненциально много способов разбить вершины на множества и при этом для общего случая не существует полиномиального алгоритма решения. Ну и даже если мы найдем какое-то решение, то проверка того, что оно лучшее возможна также лишь за экспоненциальное время. Хотя для этой задачи и известны относительно быстрые приближенные алгоритмы, нам очень трудно понять, насколько хорошее решение они дают для действительно больших графов.\n",
    "\n",
    "```{note}\n",
    "Для работы с графами мы будем пользоваться библиотекой `NetworkX`. Она написана на чистом `Python` и плохо подходит для работы с большими графами, зато имеет простой интерфейс и легко устанавливается на любую систему. Ее можно установить из репозитория `PyPI`, используя команду\n",
    "\n",
    "    pip install networkx\n",
    "\n",
    "```\n",
    "\n",
    "Одним из первых известных наборов данных для задачи выделения сообществ является \"Клуб каратэ Захари\" (Zachary’s Karate Club) {cite}`zachary1977`. Для этого набора данных точно известно, к какому из двух сообществ принадлежит каждая из вершин. В этом клубе карате был внутренний конфликт, и одна часть людей была в группе одного из инструкторов (Mr. Hi), а другая -- в группе администратора (Officer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37309518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "zachary = nx.generators.social.karate_club_graph()\n",
    "nx.draw(\n",
    "    zachary,\n",
    "    node_color=[\n",
    "        {\"Officer\": \"r\", \"Mr. Hi\": \"b\"}.get(dt[\"club\"]) for _, dt\n",
    "        in zachary.nodes(data=True)\n",
    "    ],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a35301",
   "metadata": {},
   "source": [
    "Задачу о выделении сообществ в тривиальном случае разбиения графа на два подмножества можно свести к знакомой нам задаче о максимальном разрезе. Правда, в отличие от задачи о максимальном разрезе, в случае с сообществами мы хотим иметь минимальное число ребер между ними. Но это можно сделать просто поменяв пару символов в выражении для стоимости:\n",
    "\n",
    "$$\n",
    "C = \\sum_{u,v,w \\in E} w (\\mathbf{1}(u \\in V_1, v \\in V_1) + \\mathbf{1}(u \\in V_2, v \\in V_2))\n",
    "$$\n",
    "\n",
    "Но на самом деле мы только что свели более простую задачу о минимальном разрезе с неотрицательными весами к более сложной задаче Max-Cut. А еще выбранная нами метрика (количество ребер) -- не самый лучший вариант для этой задачи. Гораздо лучше подойдет модулярность (modularity), предложенная физиком Марком Ньюманом {cite}`newman_modularity`:\n",
    "\n",
    "$$\n",
    "Q(C) = \\frac{1}{2 |E|}\\sum_{e \\in E} B_{e_{src}, e_{dst}}\\delta (c_{e_{src}}, c_{e_{dst}})\n",
    "$$\n",
    "\n",
    "Тут $B$ -- это матрица модулярности (modularity matrix). Ее элементы определяются через степени $d_i$ соответствующих вершин графа (степень вершины -- это число ребер, связанных с данной вершиной) и матрицу смежности $A$ графа:\n",
    "\n",
    "$$\n",
    "B_{ij} = A_{ij} - \\frac{d_i d_j}{2 |E|}\n",
    "$$\n",
    "\n",
    "Условно, модулярность -- это разница между числом ребер внутри сообществ в нашем графе и числом ребер внутри сообществ в графе с таким же числом ребер, но сгенерированным случайным образом. Это довольно сложное понятие, которое выходит за рамки нашего курса, но все равно потребуется нам, чтобы показать, что задача оптимизации модулярности может быть сформулирована как задача Изинга.\n",
    "\n",
    "```{note}\n",
    "Это интересно, но одним из первых алгоритмов для решения задачи о выделении сообществ в графах был алгоритм имитации отжига, который изначально был создан именно для решения проблемы гамильтонианов типа Изинга. Причина заключается в том, что модулярность очень схожа по виду с выражением энергии для магнетиков.\n",
    "```\n",
    "\n",
    "Мы тут пока описали лишь простой случай модулярности для не взвешенного и ненаправленного графа. Но даже в таком случае для задачи точной оптимизации модулярности не известно полиномиального алгоритма решения. Поэтому обычно применяют приближенные или жадные алгоритмы, и они вроде даже неплохо работают. Но мы почти не знаем, насколько действительно далеко они от самых оптимальных решений, особенно для больших графов.\n",
    "\n",
    "## Задача о Гамильтоновых циклах\n",
    "\n",
    "Перед тем как перейти к интересной и важной задаче поиска Гамильтоновых циклов, мы вспомним задачу о мостах Кенигсберга (Калининграда). Ведь именно гуляя по этому городу и пытаясь решить эту задачу, Леонард Эйлер изобрел теорию графов. Суть задачи: нужно обойти все острова города, пройдя по каждому мосту лишь один раз, и вернуться на тот остров, откуда стартовал. Эйлер, создав математический аппарат теории графов, сумел доказать, что это невозможно, ну а дальше завертелось, и вот мы с вами тут.\n",
    "\n",
    "```{figure} /_static/problems/ru/copt/bridges.png\n",
    ":width: 300px\n",
    "\n",
    "Мосты Кеннингсберга, думая о которых, Эйлер изобрел теорию графов\n",
    "```\n",
    "\n",
    "Такой путь в графе, когда мы проходим по каждому ребру лишь один раз, называется Эйлеров цикл. Но нам будет более интересен схожий класс циклов -- Гамильтоновы циклы. Это такие циклы, которые проходят через каждую вершину графа ровно один раз.\n",
    "\n",
    "```{figure} /_static/problems/ru/copt/Hamilton.jpg\n",
    ":width: 350px\n",
    "\n",
    "Сер Уильям Роуэн Гамильтон, 1805 - 1865\n",
    "```\n",
    "\n",
    "Для Гамильтонова цикла мы можем ввести $N^2$ бинарных переменных $x_{i,p}$. Каждая переменная $x_{i,p}$ равна $1$, если $i$-я вершина находится на $p$-м шаге пути и $0$ если нет. Тогда легко ввести условия существования такого цикла:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\sum_p x_{i,p} = 1 \\quad \\forall i \\\\\n",
    "\\sum_i x_{i,p} = 1 \\quad \\forall p \\\\\n",
    "(x_{i, p} = 1) \\land (x_{j, p + 1} = 0) \\quad \\forall i,j \\notin E\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Тут первое условие говорит нам о том, что каждая вершина должна попасть в путь. Второе условие -- каждый шаг пути содержит строго одну вершину. Ну а третий шаг -- просто утверждение о том, что между вершинами соседних шагов пути должно быть ребро. На самом деле, эти три условия можно переписать в единую функцию стоимости:\n",
    "\n",
    "$$\n",
    "C = (1 - \\sum_i x_{i,p})^2 + (1 - \\sum_p x_{i,p})^2 + \\sum_{u,v \\notin E} x_{u,p} x_{v,p+1}\n",
    "$$\n",
    "\n",
    "Правда, в этом случае мы должны минимизировать, а не максимизировать эту величину.\n",
    "\n",
    "## Задача коммивояжера\n",
    "\n",
    "Задачу коммивояжера мы (а точнее наш смартфон) решаем каждый раз, когда строим в `Google Maps` маршрут, включающий несколько точек. Зная, как формулируется задача о гамильтоновых циклах, сформулировать задачу коммивояжера очень легко.\n",
    "\n",
    "```{figure} /_static/intro/Salesman.png\n",
    "\n",
    "Иллюстрация задачи коммивояжера\n",
    "```\n",
    "\n",
    "По сути нам требуется взять все Гамильтоновы циклы и выбрать из них тот, для которого сумма весов по содержащимся в нем ребрам будет минимальной. Но надо помнить, что цикл обязательно должен быть в первую очередь Гамильтоновым, поэтому мы добавим веса слагаемых в выражение для стоимости, причем веса, отвечающие за сам цикл, будут больше:\n",
    "\n",
    "$$\n",
    "C = A (1 - \\sum_i x_{i,p})^2 + A (1 - \\sum_p x_{i,p})^2 + A \\sum_{u,v \\notin E} x_{u,p} x_{v,p+1} + B \\sum_{u,v,w \\in E} w x_{u,p} x_{v,p+1}\n",
    "$$\n",
    "\n",
    "Тут $A,B$ это веса, которые лучше выбирать так, что $0 < Bw < A \\quad \\forall u,v,w \\in E$.\n",
    "\n",
    "```{note}\n",
    "Функции стоимости для задач и Гамильтоновых циклах и задачи коммивояжера являются все же приближением исходной формулировки, так как формально мы переходим от задачи с ограничениями к задаче без ограничений. В общем случае нет гарантии, что решение задачи без ограничений будет эквивалентно решению задачи с ограничениям. Но для целей нашей лекции и курса в целом мы опустим сложный момент исследования эквивалентности этих задач, потому что обычно оно работает вполне корректно.\n",
    "```\n",
    "\n",
    "## Задача о рюкзаке\n",
    "\n",
    "Довольно простая для понимания задача, к которой, однако, сводится огромное число куда более сложных задач. Например, именно задачей о рюкзаке является проблема оптимизации портфеля биржевых акций, или, например, оптимизации графиков работы сотрудников McDonald's, учитывая ожидаемое число посетителей и т.д.\n",
    "\n",
    "Суть задачи заключается в том, что у нас есть рюкзак ограниченного объема. А еще есть набор разных предметов -- каждый из них имеет свой объем и стоимость. Наша цель в данном случае заключается в том, чтобы найти оптимальный набор предметов так, чтобы они влезали в наш рюкзак, при этом их стоимость была бы максимально возможной.\n",
    "\n",
    "```{figure} /_static/problems/ru/copt/Knapsack.png\n",
    ":name: knapsack\n",
    ":width: 450px\n",
    "\n",
    "Иллюстрация задачи о рюкзаке.\n",
    "```\n",
    "\n",
    "Формально это можно записать следующим образом. Пускай у нас есть рюкзак объема $V$. Давайте обозначим количество экземпляров $i$-й вещи в рюкзаке переменной $x_i$, а ее объем $v_i$. Ценность $i$-го предмета обозначим как $s_i$. Решением задачи будет вектор $X$ из целых чисел $x_i$, которые при этом могут быть равны нулю -- это будет значить, что $i$-я вещь не входит в оптимальный набор. Тогда нам необходимо решить следующую задачу:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "X = \\text{argmax} \\{ \\sum_i x_i \\cdot s_i \\} \\\\\n",
    "\\sum_i x_i \\cdot w_i \\leq W\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## Классические алгоритмы\n",
    "\n",
    "Самый простой и очевидный вариант решения таких проблем -- это просто перебор всех возможных комбинаций. Но так как сложность задач растет экспоненциально ($O(N) \\sim e^{N}$), то очень быстро прямое решение (еще иногда говорят _brute force_ решение, или _brute force_ алгоритм) становится невозможным. Понятно, что можно воспользоваться какими-то эвристиками для конкретной задачи. Это приводит нас к алгоритмам типа _ветвей и границ_ (_branch and bound_) {cite}`land2010automatic`, в которых мы обычно строим дерево возможных решений и пытаемся перебирать не все подряд, а лишь \"перспективные\" ветви этого дерева, отсекая те ветки, где хороших решений точно не будет. Но сложность таких алгоритмов все равно остается экспоненциальной. Другой вариант -- это искать не обязательно самое лучше решение, а хотя бы какое-то подходящее решение (_feasible solution_, решение, которое удовлетворяет ограничениям). Это приводит нас к аппроксимационным алгоритмам, которые каким-то образом пытаются свести экспоненциальную задачу к полиномиальной, пусть и теряя в гарантированном качестве итогового решения.\n",
    "\n",
    "```{admonition} Важное замечание\n",
    "Задачи комбинаторной оптимизации нельзя точно решить на квантовом компьютере! Квантовые компьютеры лишь дают нам потенциально очень эффективные _аппроксимационные_ алгоритмы. Причем в основе этих алгоритмов лежит обычно как раз квантовое машинное обучение!\n",
    "```\n",
    "\n",
    "### Общий вид алгоритма ветвей и границ\n",
    "\n",
    "Давайте запишем как в общем виде выглядит алгоритм ветвей и границ ([источник](https://en.wikipedia.org/wiki/Branch_and_bound#Generic_version)).\n",
    "\n",
    "1. Найти любое решение $xh$ проблемы, которое бы удовлетворяло ограничениям. Сохраним значение целевой функции для этого решения: $B = f(xh)$. Оно будет определять лучшее из известных на данный момент решений.\n",
    "2. Инициализировать очередь для хранения частных решений. В этом случае разбиваем пространство возможных решений на маленькие подпространства и строим дерево потенциальных решений. Эта часть индивидуальная для каждой задачи. Например, в случае задачи о рюкзаке, можно взять начальное решение и построить две его ветви: одна будет содержать все решения, где больше одного предмета, а другая -- где его будет меньше.\n",
    "3. Выполняем итерации, пока наша очередь не пустая.\n",
    "   - взять узел $N$ из очереди;\n",
    "   - если узел $N$ представляет собой терминальный узел $x$ дерева и $f(x) < B$, то это новое лучшее известное решение; сохраняем его $B = f(x)$;\n",
    "   - если нет, то разбиваем $N$ для создания новых узлов $N_i$:\n",
    "      - если верхняя оценочная граница решений для этой ветки $bound(N_i)$ больше $B$, то ничего не делаем;\n",
    "      - в противном случае добавляем $N_i$ в очередь.\n",
    "\n",
    "В данном случае нам необходимо реализовать для конкретной задачи следующие процедуры:\n",
    "\n",
    "- построения дерева решения\n",
    "- оценки верхней границы для ветви\n",
    "\n",
    "В целом, данный алгоритм сегодня это, пожалуй, лучшее, что можем использовать, если нам необходимо точное решение. Также всегда есть опция остановить поиск до того, как мы достигнем оптимума -- в этом варианте алгоритм становится аппроксимационным.\n",
    "\n",
    "### Жадные алгоритмы\n",
    "\n",
    "Теперь давайте вернемся к аппроксимационным алгоритмам, которые работают относительно быстро, но, к сожалению, часто дают довольное плохие результаты. Ну и самым простым вариантом таких алгоритмов будет жадный алгоритм. Рассматривать его будем на примере задачи о рюкзаке. Пусть у нас есть рюкзак объема $30$ и набор предметов с их стоимостью и объемом:\n",
    "\n",
    "$$\n",
    "items = \\{(4, 370), (9, 1950), (10, 3500), (21, 6700), (17, 6100), (3, 800), (27, 8300)\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a707585",
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = 30\n",
    "items = [(4, 370), (9, 1950), (10, 3500), (21, 6700), (17, 6100), (3, 800), (27, 8300),]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438fe679",
   "metadata": {},
   "source": [
    "Наше решение будет максимально простым:\n",
    "\n",
    "1. считаем удельную стоимость предметов, то есть стоимость единицы их массы;\n",
    "2. набираем сначала самых дорогих предметов;\n",
    "3. по остаточному принципу набираем остальные предметы, отдавая предпочтения тем, которые дороже по удельной стоимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_and_score = sorted(\n",
    "    [(it[0], it[1], it[1] / it[0]) for it in items],\n",
    "    key=lambda x: x[2],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"Items, sorted by relative cost:\")\n",
    "for it in items_and_score:\n",
    "    print(f\"Weight: {it[0]}\\tCost: {it[1]}\\tRelative Cost: {it[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e053ca5",
   "metadata": {},
   "source": [
    "\"Заполняем\" рюкзак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = []\n",
    "w = capacity\n",
    "min_weight = min([it[0] for it in items_and_score])\n",
    "\n",
    "while True:\n",
    "    if w < min_weight:\n",
    "        break\n",
    "    else:\n",
    "        cand = [it for it in items_and_score if it[0] <= w][0]\n",
    "        solution.append(cand)\n",
    "        w -= cand[0]\n",
    "\n",
    "final_score = sum([it[1] for it in solution])\n",
    "final_weight = sum([it[0] for it in solution])\n",
    "\n",
    "print(f\"Final score: {final_score}\")\n",
    "print(f\"Total weight of items: {final_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37edb8d",
   "metadata": {},
   "source": [
    "В данном случае это сработало неплохо -- мы нашли действительно хорошее решение. Однако можно заметить, что решение из трех элементов `(10, 3500)` было бы более выгодным, так как итоговая ценность была бы $10500$, что на $100$ единиц больше жадного решения. Но в силу своей _жадности_ наш алгоритм не смог найти это решение, хотя найденное им и лежит довольно близко к лучшему. Так что очень часто жадные алгоритмы находят очень плохие решения, причем качество решений сильно падает с ростом размерности проблемы.\n",
    "\n",
    "### Метод имитации отжига\n",
    "\n",
    "Это итеративный алгоритм, который очень часто способен найти действительно неплохое решение. Причем, в отличие от жадных алгоритмов, отжиг специально сделан так, чтобы не \"застревать\" в каких-то локально-хороших точках пространства решений, а наоборот, искать самое лучшее. Мы разберем работу отжига на примере задачи о максимальном разрезе в графе, а именно, реализуем подобие алгоритма Метрополиса-Гастингса {cite}`hastings1970monte`. Но для начала давайте сгенерируем случайный граф:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f793ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "rand_mat = np.random.rand(10, 10)\n",
    "rand_adj = (rand_mat + rand_mat.T) / 2\n",
    "rand_adj[rand_adj < 0.35] = 0.0\n",
    "np.fill_diagonal(rand_adj, 0)\n",
    "\n",
    "g = nx.Graph(rand_adj)\n",
    "nx.draw(g)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c5178",
   "metadata": {},
   "source": [
    "Напомню, что цель состоит в том, чтобы разбить множество вершин на два подмножества так, чтобы сумма весов ребер между двумя подмножествами была максимальной. Для этого понадобится функция, которая считает целевое значение для любого разбиения на два подмножества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4615b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(g: nx.classes.graph.Graph, x: List[int]) -> (float):\n",
    "    score = 0\n",
    "    for e in g.edges(data=True):\n",
    "        if x[e[0]] != x[e[1]]:\n",
    "            score += e[2][\"weight\"]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ba073",
   "metadata": {},
   "source": [
    "Разобьем вершины на две группы случайным образом несколько раз и проверим, что функция работает корректно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5698d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_random_node(random_seed: int) -> (List[int]):\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    random_x = [\n",
    "        1 if np.random.random() <= 0.5 else -1\n",
    "        for _ in range(g.number_of_nodes())\n",
    "    ]\n",
    "    print(f\"Random seed {random_seed}\\tScore: {score(g, random_x):.2f}\")\n",
    "\n",
    "    return random_x\n",
    "\n",
    "for random_seed in [2019, 2020, 2021]:\n",
    "    random_x = split_random_node(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92002cc",
   "metadata": {},
   "source": [
    "Суть процесса отжига заключается в следующем:\n",
    "\n",
    "1. генерируем начальное случайное решение (или получаем _feasible_ при помощи эвристик);\n",
    "2. задаем начальную \"температуру\" -- некий глобальный метапараметр, суть которого станет ясна далее;\n",
    "2. выполняем отжиг заданное число итераций;\n",
    "    - выполняем случайую модификацию решения;\n",
    "    - если значение функции стоимости для нового решения лучше, чем для старого, то принимаем его;\n",
    "    - если нет, то все равно можем принять новое решение, но лишь с некоторой вероятностью, которая тем больше, чем выше температура и чем ближе друг к другу по оценке старое и новое решение.\n",
    "\n",
    "Давайте реализуем это. В качестве функции, которая дает нам вероятность принять/отклонить новое решение, будем использовать [распределение Больцмана](https://en.wikipedia.org/wiki/Boltzmann_distribution):\n",
    "\n",
    "$$\n",
    "P_{acceptance} = e^{\\frac{E_{new} - E_{old}}{T}}\n",
    "$$\n",
    "\n",
    "Видно, что эта величина может быть больше единицы в случае, когда новое решение лучше старого, но для нас это не проблема -- это просто будет значить, что мы точно принимаем новое решение!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "e_history = []\n",
    "x = random_x\n",
    "T = T_0 = 100\n",
    "e = score(g, x)\n",
    "e_history.append(e)\n",
    "\n",
    "def bolzman(e_old: float, e_new: float, T: Union[int, float]) -> (float):\n",
    "    return np.exp((e_new - e_old) / T)\n",
    "\n",
    "def permute(x: List[int]) -> (List[int]):\n",
    "    i = np.random.randint(0, len(x) - 1)\n",
    "    x_new = copy(x)\n",
    "    x_new[i] *= -1\n",
    "\n",
    "    return x_new\n",
    "\n",
    "for i in range(1500):\n",
    "    new_state = permute(x)\n",
    "    new_e = score(g, new_state)\n",
    "\n",
    "    if new_e > e:\n",
    "        e = new_e\n",
    "        x = new_state\n",
    "    else:\n",
    "        prob = bolzman(e, new_e, T)\n",
    "        if np.random.rand() <= prob:\n",
    "            e = new_e\n",
    "            x = new_state\n",
    "\n",
    "    e_history.append(e)\n",
    "    T = T_0 / (i + 1)\n",
    "\n",
    "print(f\"Final energy: {e:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f32556",
   "metadata": {},
   "source": [
    "И посмотрим, как оно сходилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2729ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(e_history)), e_history, \".-\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e43f3f",
   "metadata": {},
   "source": [
    "Видим, что в начале у нас был активный поиск решения, а ближе к концу переходы становились возможны, лишь если новое решение лучше. Этот процесс чем-то похож на кристаллизацию расплавов, когда изначально все частицы плавают в жидкости, но с уменьшением температуры они все более точно становится в те позиции, которые обеспечивают минимум свободной энергии кристалла. Именно поэтому данный алгоритм называется _имитацией отжига_ (_simulated annealing_).\n",
    "\n",
    "Этот алгоритм неплохо находит оптимальные решение, но с ростом размерности задачи, а также пространства решений процесс \"отжига\" должен длиться все дольше и дольше, а температура уменьшаться все медленней.\n",
    "\n",
    "## Заключение\n",
    "\n",
    "В этой лекции мы узнали, что же это за такие _NP_-задачи, а также познакомились с примерами некоторых из них. Посмотрели, как эти задачи можно решать на классическом компьютере, и какие при этом есть ограничения. В следующих лекциях мы узнаем:\n",
    "\n",
    "- как задачи комбинаторной оптимизации можно свести к решению модели Изинга (подробнее об этой модели -- в [отдельной лекции](../../problems/ru/ising.md))\n",
    "- как задача Изинга переходит в задачу об основном состоянии квантовой системы\n",
    "- как задачу об основном состоянии можно решать на квантовом компьютере разными способами:\n",
    "  - через алгоритм _VQE_, основанном на [вариационных квантовых схемах](../../vqc/ru/vqc.md)\n",
    "  - через алгоритм _QAOA_, который является квантовым аналогом алгоритма имитации отжига\n",
    "  - на специальных квантовых компьютерах -- [квантовых аннилерах](../../dwave/ru/dwave.md)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   11,
   65,
   79,
   222,
   225,
   233,
   243,
   247,
   265,
   273,
   289,
   293,
   300,
   304,
   318,
   337,
   373,
   377,
   382
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}