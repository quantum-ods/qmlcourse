{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b77668",
   "metadata": {},
   "source": [
    "(qconv)=\n",
    "\n",
    "# Сверточные вариационные квантовые схемы\n",
    "\n",
    "Автор(ы):\n",
    "\n",
    "- [Петров Вадим](https://github.com/belgraviton)\n",
    "\n",
    "\n",
    "## Описание лекции\n",
    "\n",
    "На этой лекции мы рассмотрим аналог сверточных слоев нейронной сети и приведем пример их использования. Лекция расскажет:\n",
    "- как работают \"классические\" свертки в нейронных сетях;\n",
    "- что такое сверточные вариационные квантовые схемы;\n",
    "- как их можно использовать для задач машинного обучения на примере датасета MNIST.\n",
    "\n",
    "## Сверточные нейронные сети\n",
    "\n",
    "Данный тип нейронных сетей нацелен на обработку изображений и представляет из себя последовательный набор `сверточных слоев`, чередующиеся с другими вспомогательными слоями, например, с функциями нелинейного преобразования (активациями). Пример работы `сверточного слоя` представлен на рисунке ниже.\n",
    "\n",
    "```{figure} /_static/qnn/ru/2D_Convolution_Animation.gif\n",
    ":name: 2D_Convolution_Animation\n",
    "\n",
    "Классическая свертка\n",
    "```\n",
    "\n",
    "Свое название `сверточный слой` получил из-за наличия операции свертки (конволюции), суть которой в том, что каждый фрагмент входного изображения (input) умножается на матрицу (ядро размера 3х3, kernel) свертки поэлементно, а результат суммируется и записывается в аналогичную позицию выходного изображения (output).\n",
    "\n",
    "`Сверточные слои` являются ключевыми элементами алгоритмов по распознаванию и классификации изображений. Большинство успехов в области компьютерного зрения за последнее десятилетие связано именно с ними.\n",
    "\n",
    "## Квантовая свертка\n",
    "\n",
    "Активное развитие квантовых вычислений создает запрос на построение квантового аналога светки. Работа [(Henderson M. et.al., 2019)](https://arxiv.org/abs/1904.04767), описывающая подобный подход, предлагает следующую схему реализации на основе вариационных квантовых схем:\n",
    " - изображение разбивается на блоки размера 2х2;\n",
    " - для каждого блока осуществляется кодирование входного сигнала к квантовому состоянию, которое в данной лекции осуществляется параметризованным вращением кубита из основного состояния;\n",
    " - квантовые вычисления выполняются над входными кубитами посредством случайной квантовой цепи;\n",
    " - проводится измерение квантовой системы для получения классических величин;\n",
    " - выполняя данную процедуру для всех 2х2 областей на выходе получается многоканальное изображение (четырехканальное на примере ниже), которое будет использоваться в следующих слоях классической или квантовой нейронной сети.\n",
    "\n",
    "```{figure} /_static/qnn/ru/qconv_net4.png\n",
    ":name: qconv_net4\n",
    ":width: 700px\n",
    "\n",
    "Квантовая свертка\n",
    "```\n",
    "\n",
    "Основное отличие по отношению к классической свертке состоит в том, что квантовая схема может генерировать очень сложные ядра, вычисления которых могут быть классически невоспроизводимыми. Указанные сложные ядра, а именно ядра в высокоразмерном пространстве Гильберта, могут дать преимущества квантовым сверткам по отношению к классическим.\n",
    "\n",
    "Пример реализации и работы такого блока квантовой свертки будет продемонстрирован ниже.\n",
    "\n",
    "## Подготовка модели и данных\n",
    "\n",
    "Пример кода реализации гибридной квантово-классической сети с квантовым сверточным слоем взят из [документации](https://pennylane.ai/qml/demos/tutorial_quanvolution.html) библиотеки `PennyLane` с небольшими изменениями.\n",
    "\n",
    "Сначала загружаем библиотеки `PennyLane` для квантовых вычислений, `tensorflow` для обучения классификатора и `matplotlib` для отрисовки результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bf27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073f9ae",
   "metadata": {},
   "source": [
    "Устанавливаем параметры модели для обучения: число эпох, число слоев квантовой свертки и его выходных каналов, а также число тренировочных и тестовых примеров. Нужно использовать 4 кубита, для обработки каждого из 4 пикселей входного блока и генерации 4 каналов.  Число примеров выбрано малым для увеличения скорости демонстрации. Также фиксируем инициализацию генераторов случайных чисел для `numpy` и `tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c432984",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20   # Количество эпох обучения\n",
    "n_layers = 1    # Число случайных квантовых блоков\n",
    "n_wires = 4     # Число выходных каналов после квантовых блоков\n",
    "n_train = 20    # Размер тренировочного датасета\n",
    "n_test = 10     # Размер тестового датасета\n",
    "\n",
    "# Инициализация генераторов случайных чисел\n",
    "np.random.seed(0)  \n",
    "tf.random.set_seed(255)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d655a5c",
   "metadata": {},
   "source": [
    "Для демонстрации используем датасет MNIST, который создан для предсказания цифры (от 0 до  9) по его изображению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "\n",
    "# Ограничение размера датасета\n",
    "train_images = train_images[:n_train]\n",
    "train_labels = train_labels[:n_train]\n",
    "test_images = test_images[:n_test]\n",
    "test_labels = test_labels[:n_test]\n",
    "\n",
    "# Нормализация изображений из диапазона (0, 255) в (0, 1)\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255\n",
    "\n",
    "# Добавление дополнительной размерности к данным для сверточных каналов\n",
    "train_images = np.array(train_images[..., tf.newaxis], requires_grad=False)\n",
    "test_images = np.array(test_images[..., tf.newaxis], requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c96bab5",
   "metadata": {},
   "source": [
    "## Случайная квантовая цепь\n",
    "\n",
    "В качестве блока квантовой свертки используется **случайная квантовая цепь** (RandomLayers в `PennyLane`). Блок реализуется путем случайного выбора для части кубитов операций вращения, а для части пар кубитов парных квантовых гейтов. На последнем этапе генерации блока осуществляется случайное перемешивание очередности применения операций.\n",
    "\n",
    "В нашем примере случайная квантовая цепь обрабатывает 4 кубита. Таким образом часть из 4 кубитов получит какие-либо операции вращения, а часть из 6 пар кубитов - гейты. Финальная очередность операций будет случайной.\n",
    "\n",
    "Следует заметить, что в нашем примере используется фиксированный (необучаемый) блок случайной квантовой цепи. Он будет использован как блок препроцессинга. В будущем, когда в библиотеке будет реализована возможность расчета градиентов и изменения параметров блока на их основании, указанный блок тоже можно будет обучать.\n",
    "\n",
    "## Реализация квантовой свертки\n",
    "\n",
    "Далее создаем устройство, симулирующее работу 4 кубитов. Оно состоит из трех частей:\n",
    "- кодировщик, преобразующий входные данные в квантовые состояния с помощью $RY$ поворотов;\n",
    "- случайная квантовая цепь;\n",
    "- измерения, дающие 4 выходных значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b170bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_wires)\n",
    "\n",
    "# Генерация значений параметров для квантовых слоев\n",
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, n_wires))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(phi):\n",
    "    # Кодирование 4 классических входных данных\n",
    "    for j in range(n_wires):\n",
    "        qml.RY(np.pi * phi[j], wires=j)\n",
    "\n",
    "    # Случайная квантовая цепь\n",
    "    RandomLayers(rand_params, wires=list(range(n_wires)))\n",
    "\n",
    "    # Измерения, которые дают 4 классических выходных значений для следующих слоев\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(n_wires)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb059ee",
   "metadata": {},
   "source": [
    "Следующая функция `quanv` определяет квантовую свертку по следующей схеме:\n",
    "- разделение изображения на блоки 2х2 пикселей;\n",
    "- обработку каждого блока квантовой цепью `circuit`, описанной выше;\n",
    "- 4 выходных значения для каждого блока помещаются в 4 разных канала одного пикселя выходного изображения.\n",
    "\n",
    "Описанный выше процесс уменьшает разрешение входного изображения в 2 раза, что эквивалентно классической свертки с ядром 2х2 и шагом 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed67cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quanv(image):\n",
    "    \"\"\"Функция квантовой свертки над входным изображением.\"\"\"\n",
    "\n",
    "    out = np.zeros((14, 14, n_wires))\n",
    "\n",
    "    # Циклы по координатам верхнего левого пикселя блоков 2х2\n",
    "    for j in range(0, 28, 2):\n",
    "        for k in range(0, 28, 2):\n",
    "            # Обработка блока 2x2 из изображения квантовой цепью\n",
    "            q_results = circuit(\n",
    "                [\n",
    "                    image[j, k, 0],\n",
    "                    image[j, k + 1, 0],\n",
    "                    image[j + 1, k, 0],\n",
    "                    image[j + 1, k + 1, 0]\n",
    "                ]\n",
    "            )\n",
    "            # Запись результатов наблюдения в выходной пиксель (j/2, k/2)\n",
    "            for c in range(n_wires):\n",
    "                out[j // 2, k // 2, c] = q_results[c]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24bb04f",
   "metadata": {},
   "source": [
    "## Подготовка датасета\n",
    "\n",
    "Так как квантовый сверточный слой в нашем случае не обучается, то лучше провести предварительную обработку им всех используемых изображений из датасета. Подготовленные данные будут использоваться классической нейронной сетью для обучения модели классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec57992",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_train_images = []\n",
    "for idx, img in enumerate(train_images):\n",
    "    q_train_images.append(quanv(img))\n",
    "q_train_images = np.asarray(q_train_images)\n",
    "print(\"Препроцессинг тренировочных изображений квантовой сверткой выполнен.\")\n",
    "\n",
    "q_test_images = []\n",
    "for idx, img in enumerate(test_images):\n",
    "    q_test_images.append(quanv(img))\n",
    "q_test_images = np.asarray(q_test_images)\n",
    "print(\"Препроцессинг тестовых изображений квантовой сверткой выполнен.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ab540",
   "metadata": {},
   "source": [
    "Давайте посмотрим на 4 первых тренировочных примера (первый ряд) и их 4 канала подготовленных данных (2-5 строки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c9781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 4\n",
    "n_channels = n_wires\n",
    "fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
    "\n",
    "for k in range(n_samples):\n",
    "    axes[0, 0].set_ylabel(\"Input\")\n",
    "    if k != 0:\n",
    "        axes[0, k].yaxis.set_visible(False)\n",
    "    axes[0, k].imshow(train_images[k, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "    # Отрисовка\n",
    "    for c in range(n_channels):\n",
    "        axes[c + 1, 0].set_ylabel(f\"Output [ch. {c}]\")\n",
    "        if k != 0:\n",
    "            axes[c, k].yaxis.set_visible(False)\n",
    "        axes[c + 1, k].imshow(q_train_images[k, :, :, c], cmap=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a30aa",
   "metadata": {},
   "source": [
    "По обработанным данным (последние 4 ряда) видно уменьшение разрешения в 2 раза, а также то, что пространственная структура цифр сохраняется, что и должно наблюдаться для сверточных слоев\n",
    "\n",
    "## Гибридная квантово-классическая модель\n",
    "\n",
    "Ниже опишем классическую часть нейронной сети, которая будет обучена для классификации 10 цифр. Будет использована очень простая модель, основанная на одном полносвязном слое и финальном применении функции softmax, которая выдает вероятности представленных 10 классов.\n",
    "\n",
    "Обучение будет осуществлено с помощью оптимизатора `Adam` по функции потерь, в качестве которой используется кросс-энтропия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel():\n",
    "    \"\"\"Функция инициализирует и возвращает keras модель, готовая к обучению\"\"\"\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d2dec",
   "metadata": {},
   "source": [
    "## Тренировка моделей\n",
    "\n",
    "Сначала обучим модель на данных, подготовленных с помощью квантовой цепи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = MyModel()\n",
    "\n",
    "q_history = q_model.fit(\n",
    "    q_train_images,\n",
    "    train_labels,\n",
    "    validation_data=(q_test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7744c421",
   "metadata": {},
   "source": [
    "Для сравнения с результатами чисто классической модели проведем ее обучение на входных необработанных картинках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model = MyModel()\n",
    "\n",
    "c_history = c_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43089783",
   "metadata": {},
   "source": [
    "## Сравнение результатов\n",
    "\n",
    "Сравнение проведем на основе тестовой точности и значению функции потерь в зависимости от номера эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2276fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax1.plot(q_history.history[\"val_accuracy\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax1.plot(c_history.history[\"val_accuracy\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(q_history.history[\"val_loss\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax2.plot(c_history.history[\"val_loss\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_ylim(top=2.5)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aff82e",
   "metadata": {},
   "source": [
    "Из рисунков видно наличие сильного сходства результатов для двух моделей: гибридной и чисто классической. В наших малых экспериментах достигнута довольно низкая точность в 50% (классический аналог - 40%). Однако при увеличении числа используемых примеров точность должна быть существенно выше.\n",
    "\n",
    "## Замечания\n",
    "\n",
    "- в статье авторов подхода [(Henderson M. et.al., 2019)](https://arxiv.org/abs/1904.04767) для гибридной и чисто классической сети с большим количеством слоев (см. схему сети) и большим объемом данных, достигнута ожидаемая высокая точность выше 95%;\n",
    "- блоки квантовой свертки сейчас особо интересны, так как они ориентированы на использование малого количества кубитов, которое доступно в текущий период времени для устройств с промежуточным количеством кубитов (NISQ).\n",
    "\n",
    "## Что мы узнали из лекции\n",
    "\n",
    "- существует аналог сверточных нейронных сетей для квантовых вычислений;\n",
    "- аналог квантовой свертки может быть реализован с использованием случайной квантовой цепи;\n",
    "- использование квантовой свертки позволяет достичь результатов схожих с классическими сетями;\n",
    "- основное преимущество квантовой свертки по отношению к классической в том, что первая является более широкой операцией, которая не может быть описана классическим случаем."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   11,
   70,
   82,
   87,
   97,
   102,
   119,
   137,
   154,
   164,
   186,
   193,
   205,
   210,
   230,
   241,
   256,
   263,
   274,
   279,
   290,
   297,
   316
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}